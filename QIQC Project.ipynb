{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efdd7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# doVarMERA.py\n",
    "# ---------------------------------------------------------------------\n",
    "# Variational energy minimization of (scale-invariant) modified binary MERA\n",
    "#\n",
    "# by Glen Evenbly (c) for www.tensors.net, (v1.2) - last modified 6/2019\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from ncon import ncon\n",
    "\n",
    "\n",
    "def doVarMERA(hamAB, hamBA, rhoAB, rhoBA, wC, vC, uC, chi, chimid, OPTS):\n",
    "  \"\"\"\n",
    "  Variational energy minimization of (scale-invariant) modified binary MERA\n",
    "  for nearest neighbour 1D Hamiltonian. Inputs 'hamAB, hamBA, rhoAB, rhoBA,\n",
    "  wC, vC, uC' are lists whose lengths are equal to the number of MERA\n",
    "  levels. Input Hamiltonian specified through 'hamAB[0]' and 'hamBA[0]'.\n",
    "  Bond dimensions specified through 'chi' and 'chimid'.\n",
    "\n",
    "  OPTS is a dict containing the optional arguments:\n",
    "    numiter: int=1000, number of variatonal iterations\n",
    "    refsym: bool=True, impose reflection symmetry\n",
    "    numtrans: int=2, number of transitional layers\n",
    "    dispon: bool=True, specify wether or not to display convergence data\n",
    "    E0: float=0.0, specify exact ground energy (if known)\n",
    "    sciter: int=4, iterations of power method to find rho\n",
    "  \"\"\"\n",
    "  if 'numiter' not in OPTS:\n",
    "    OPTS['numiter'] = 1000\n",
    "  if 'numtrans' not in OPTS:\n",
    "    OPTS['numtrans'] = 2\n",
    "  if 'refsym' not in OPTS:\n",
    "    OPTS['refsym'] = True\n",
    "  if 'dispon' not in OPTS:\n",
    "    OPTS['dispon'] = True\n",
    "  if 'sciter' not in OPTS:\n",
    "    OPTS['sciter'] = 4\n",
    "  if 'E0' not in OPTS:\n",
    "    OPTS['E0'] = 0\n",
    "\n",
    "  # Add extra layers if required\n",
    "  totLv = OPTS['numtrans'] + 1\n",
    "  for k in range(totLv - len(wC)):\n",
    "    wC.append(wC[-1])\n",
    "    vC.append(vC[-1])\n",
    "    uC.append(uC[-1])\n",
    "\n",
    "  for k in range(1 + totLv - len(hamAB)):\n",
    "    hamAB.append(hamAB[-1])\n",
    "    hamBA.append(hamBA[-1])\n",
    "    rhoAB.append(rhoAB[-1])\n",
    "    rhoBA.append(rhoBA[-1])\n",
    "\n",
    "  # Expand tensors to new dimensions if required\n",
    "  chiZ = np.zeros(totLv + 1, dtype=int)\n",
    "  chiZ[0] = hamAB[0].shape[0]\n",
    "  chimidZ = np.zeros(totLv + 1, dtype=int)\n",
    "  chimidZ[0] = hamAB[0].shape[0]\n",
    "  for k in range(totLv):\n",
    "    chiZ[k + 1] = min(chi, chiZ[k] * chimidZ[k])\n",
    "    chimidZ[k + 1] = min(chimid, chiZ[k])\n",
    "    wC[k] = TensorExpand(wC[k], [chiZ[k], chimidZ[k + 1], chiZ[k + 1]])\n",
    "    vC[k] = TensorExpand(vC[k], [chiZ[k], chimidZ[k + 1], chiZ[k + 1]])\n",
    "    uC[k] = TensorExpand(uC[k],\n",
    "                         [chiZ[k], chiZ[k], chimidZ[k + 1], chimidZ[k + 1]])\n",
    "    hamAB[k + 1] = TensorExpand(\n",
    "        hamAB[k + 1], [chiZ[k + 1], chiZ[k + 1], chiZ[k + 1], chiZ[k + 1]])\n",
    "    hamBA[k + 1] = TensorExpand(\n",
    "        hamBA[k + 1], [chiZ[k + 1], chiZ[k + 1], chiZ[k + 1], chiZ[k + 1]])\n",
    "    rhoAB[k + 1] = TensorExpand(\n",
    "        rhoAB[k + 1], [chiZ[k + 1], chiZ[k + 1], chiZ[k + 1], chiZ[k + 1]])\n",
    "    rhoBA[k + 1] = TensorExpand(\n",
    "        rhoBA[k + 1], [chiZ[k + 1], chiZ[k + 1], chiZ[k + 1], chiZ[k + 1]])\n",
    "\n",
    "  # Ensure Hamiltonian is negative defined\n",
    "  hamABstart = hamAB[0]\n",
    "  hamBAstart = hamBA[0]\n",
    "  bias = max(LA.eigvalsh(hamAB[0].reshape(chiZ[0]**2, chiZ[0]**2)))\n",
    "  hamAB[0] = hamAB[0] - bias * np.eye(chiZ[0]**2).reshape(\n",
    "      chiZ[0], chiZ[0], chiZ[0], chiZ[0])\n",
    "  hamBA[0] = hamBA[0] - bias * np.eye(chiZ[0]**2).reshape(\n",
    "      chiZ[0], chiZ[0], chiZ[0], chiZ[0])\n",
    "\n",
    "  Energy = 0\n",
    "  for k in range(OPTS['numiter']):\n",
    "    # Find scale-invariant density matrix (via power method)\n",
    "    for g in range(OPTS['sciter']):\n",
    "      rhoABtemp, rhoBAtemp = DescendSuper(rhoAB[totLv], rhoBA[totLv],\n",
    "                                          wC[totLv - 1], vC[totLv - 1],\n",
    "                                          uC[totLv - 1], OPTS['refsym'])\n",
    "      rhoAB[totLv] = 0.5 * (rhoABtemp + np.conj(\n",
    "          rhoABtemp.transpose(2, 3, 0, 1))) / ncon([rhoABtemp], [[1, 2, 1, 2]])\n",
    "      rhoBA[totLv] = 0.5 * (rhoBAtemp + np.conj(\n",
    "          rhoBAtemp.transpose(2, 3, 0, 1))) / ncon([rhoBAtemp], [[1, 2, 1, 2]])\n",
    "      if OPTS['refsym']:\n",
    "        rhoAB[totLv] = 0.5 * rhoAB[totLv] + 0.5 * rhoAB[totLv].transpose(\n",
    "            1, 0, 3, 2)\n",
    "        rhoBA[totLv] = 0.5 * rhoBA[totLv] + 0.5 * rhoBA[totLv].transpose(\n",
    "            1, 0, 3, 2)\n",
    "\n",
    "    # Descend density matrix through all layers\n",
    "    for p in range(totLv - 1, -1, -1):\n",
    "      rhoAB[p], rhoBA[p] = DescendSuper(rhoAB[p + 1], rhoBA[p + 1], wC[p],\n",
    "                                        vC[p], uC[p], OPTS['refsym'])\n",
    "\n",
    "    # Compute energy and display\n",
    "    if OPTS['dispon']:\n",
    "      if np.mod(k, 10) == 1:\n",
    "        Energy = (ncon([rhoAB[0], hamAB[0]], [[1, 2, 3, 4], [1, 2, 3, 4]]) +\n",
    "                  ncon([rhoBA[0], hamBA[0]],\n",
    "                       [[1, 2, 3, 4], [1, 2, 3, 4]])) / 4 + bias / 2\n",
    "        ExpectX = ncon([\n",
    "            rhoAB[0].reshape(2, 2, 2, 2, 2, 2, 2, 2),\n",
    "            np.array([[0, 1], [1, 0]])\n",
    "        ], [[4, 1, 2, 3, 5, 1, 2, 3], [4, 5]])\n",
    "\n",
    "        print('Iteration: %d of %d, Energy: %f, Err: %e, Mag: %e' %\n",
    "              (k, OPTS['numiter'], Energy, Energy - OPTS['E0'], ExpectX))\n",
    "\n",
    "    # Optimise over all layers\n",
    "    for p in range(totLv):\n",
    "      if k > 9:\n",
    "        uEnv = DisEnv(hamAB[p], hamBA[p], rhoBA[p + 1], wC[p], vC[p], uC[p],\n",
    "                      OPTS['refsym'])\n",
    "        if OPTS['refsym']:\n",
    "          uEnv = uEnv + uEnv.transpose(1, 0, 3, 2)\n",
    "\n",
    "        uC[p] = TensorUpdateSVD(uEnv, 2)\n",
    "\n",
    "      if k > 1:\n",
    "        wEnv = IsoEnvW(hamAB[p], hamBA[p], rhoBA[p + 1], rhoAB[p + 1], wC[p],\n",
    "                       vC[p], uC[p])\n",
    "        wC[p] = TensorUpdateSVD(wEnv, 2)\n",
    "        if OPTS['refsym']:\n",
    "          vC[p] = wC[p]\n",
    "        else:\n",
    "          vEnv = IsoEnvV(hamAB[p], hamBA[p], rhoBA[p + 1], rhoAB[p + 1], wC[p],\n",
    "                         vC[p], uC[p])\n",
    "          vC[p] = TensorUpdateSVD(vEnv, 2)\n",
    "\n",
    "      hamAB[p + 1], hamBA[p + 1] = AscendSuper(hamAB[p], hamBA[p], wC[p], vC[p],\n",
    "                                               uC[p], OPTS['refsym'])\n",
    "\n",
    "  hamAB[0] = hamABstart\n",
    "  hamBA[0] = hamBAstart\n",
    "\n",
    "  return Energy, hamAB, hamBA, rhoAB, rhoBA, wC, vC, uC\n",
    "\n",
    "\n",
    "def AscendSuper(hamAB, hamBA, w, v, u, refsym):\n",
    "  \"\"\" apply the average ascending superoperator to the Hamiltonian \"\"\"\n",
    "\n",
    "  indList1 = [[6, 4, 1, 2], [1, 3, -3], [6, 7, -1], [2, 5, 3, 9], [4, 5, 7, 10],\n",
    "              [8, 9, -4], [8, 10, -2]]\n",
    "  indList2 = [[3, 4, 1, 2], [5, 6, -3], [5, 7, -1], [1, 2, 6, 9], [3, 4, 7, 10],\n",
    "              [8, 9, -4], [8, 10, -2]]\n",
    "  indList3 = [[5, 7, 2, 1], [8, 9, -3], [8, 10, -1], [4, 2, 9, 3],\n",
    "              [4, 5, 10, 6], [1, 3, -4], [7, 6, -2]]\n",
    "  indList4 = [[3, 6, 2, 5], [2, 1, -3], [3, 1, -1], [5, 4, -4], [6, 4, -2]]\n",
    "\n",
    "  hamBAout = ncon(\n",
    "      [hamAB, w, np.conj(w), u,\n",
    "       np.conj(u), v, np.conj(v)], indList1)\n",
    "  if refsym:\n",
    "    hamBAout = hamBAout + hamBAout.transpose(1, 0, 3, 2)\n",
    "  else:\n",
    "    hamBAout = hamBAout + ncon(\n",
    "        [hamAB, w, np.conj(w), u,\n",
    "         np.conj(u), v, np.conj(v)], indList3)\n",
    "\n",
    "  hamBAout = hamBAout + ncon(\n",
    "      [hamBA, w, np.conj(w), u,\n",
    "       np.conj(u), v, np.conj(v)], indList2)\n",
    "  hamABout = ncon([hamBA, v, np.conj(v), w, np.conj(w)], indList4)\n",
    "\n",
    "  return hamABout, hamBAout\n",
    "\n",
    "\n",
    "def DescendSuper(rhoAB, rhoBA, w, v, u, refsym):\n",
    "  \"\"\" apply the average descending superoperator to the density matrix \"\"\"\n",
    "\n",
    "  indList1 = [[9, 3, 4, 2], [-3, 5, 4], [-1, 10, 9], [-4, 7, 5, 6],\n",
    "              [-2, 7, 10, 8], [1, 6, 2], [1, 8, 3]]\n",
    "  indList2 = [[3, 6, 2, 5], [1, 7, 2], [1, 9, 3], [-3, -4, 7, 8],\n",
    "              [-1, -2, 9, 10], [4, 8, 5], [4, 10, 6]]\n",
    "  indList3 = [[3, 9, 2, 4], [1, 5, 2], [1, 8, 3], [7, -3, 5, 6], [7, -1, 8, 10],\n",
    "              [-4, 6, 4], [-2, 10, 9]]\n",
    "  indList4 = [[3, 6, 2, 5], [-3, 1, 2], [-1, 1, 3], [-4, 4, 5], [-2, 4, 6]]\n",
    "\n",
    "  rhoABout = 0.5 * ncon(\n",
    "      [rhoBA, w, np.conj(w), u,\n",
    "       np.conj(u), v, np.conj(v)], indList1)\n",
    "  if refsym:\n",
    "    rhoABout = rhoABout + rhoABout.transpose(1, 0, 3, 2)\n",
    "  else:\n",
    "    rhoABout = rhoABout + 0.5 * ncon(\n",
    "        [rhoBA, w, np.conj(w), u,\n",
    "         np.conj(u), v, np.conj(v)], indList3)\n",
    "\n",
    "  rhoBAout = 0.5 * ncon(\n",
    "      [rhoBA, w, np.conj(w), u,\n",
    "       np.conj(u), v, np.conj(v)], indList2)\n",
    "  rhoBAout = rhoBAout + 0.5 * ncon(\n",
    "      [rhoAB, v, np.conj(v), w, np.conj(w)], indList4)\n",
    "\n",
    "  return rhoABout, rhoBAout\n",
    "\n",
    "\n",
    "def DisEnv(hamAB, hamBA, rhoBA, w, v, u, refsym):\n",
    "  \"\"\" compute the environment of a disentangler \"\"\"\n",
    "\n",
    "  indList1 = [[7, 8, 10, -1], [4, 3, 9, 2], [10, -3, 9], [7, 5, 4],\n",
    "              [8, -2, 5, 6], [1, -4, 2], [1, 6, 3]]\n",
    "  indList2 = [[7, 8, -1, -2], [3, 6, 2, 5], [1, -3, 2], [1, 9, 3],\n",
    "              [7, 8, 9, 10], [4, -4, 5], [4, 10, 6]]\n",
    "  indList3 = [[7, 8, -2, 10], [3, 4, 2, 9], [1, -3, 2], [1, 5, 3],\n",
    "              [-1, 7, 5, 6], [10, -4, 9], [8, 6, 4]]\n",
    "\n",
    "  uEnv = ncon(\n",
    "      [hamAB, rhoBA, w, np.conj(w),\n",
    "       np.conj(u), v, np.conj(v)], indList1)\n",
    "  if refsym:\n",
    "    uEnv = uEnv + uEnv.transpose(1, 0, 3, 2)\n",
    "  else:\n",
    "    uEnv = uEnv + ncon(\n",
    "        [hamAB, rhoBA, w,\n",
    "         np.conj(w), np.conj(u), v,\n",
    "         np.conj(v)], indList3)\n",
    "\n",
    "  uEnv = uEnv + ncon(\n",
    "      [hamBA, rhoBA, w, np.conj(w),\n",
    "       np.conj(u), v, np.conj(v)], indList2)\n",
    "\n",
    "  return uEnv\n",
    "\n",
    "\n",
    "def IsoEnvW(hamAB, hamBA, rhoBA, rhoAB, w, v, u):\n",
    "  \"\"\" compute the environment of a 'w'-isometry \"\"\"\n",
    "\n",
    "  indList1 = [[7, 8, -1, 9], [4, 3, -3, 2], [7, 5, 4], [9, 10, -2, 11],\n",
    "              [8, 10, 5, 6], [1, 11, 2], [1, 6, 3]]\n",
    "  indList2 = [[1, 2, 3, 4], [10, 7, -3, 6], [-1, 11, 10], [3, 4, -2, 8],\n",
    "              [1, 2, 11, 9], [5, 8, 6], [5, 9, 7]]\n",
    "  indList3 = [[5, 7, 3, 1], [10, 9, -3, 8], [-1, 11, 10], [4, 3, -2, 2],\n",
    "              [4, 5, 11, 6], [1, 2, 8], [7, 6, 9]]\n",
    "  indList4 = [[3, 7, 2, -1], [5, 6, 4, -3], [2, 1, 4], [3, 1, 5], [7, -2, 6]]\n",
    "\n",
    "  wEnv = ncon(\n",
    "      [hamAB, rhoBA, np.conj(w), u,\n",
    "       np.conj(u), v, np.conj(v)], indList1)\n",
    "  wEnv = wEnv + ncon(\n",
    "      [hamBA, rhoBA, np.conj(w), u,\n",
    "       np.conj(u), v, np.conj(v)], indList2)\n",
    "  wEnv = wEnv + ncon(\n",
    "      [hamAB, rhoBA, np.conj(w), u,\n",
    "       np.conj(u), v, np.conj(v)], indList3)\n",
    "  wEnv = wEnv + ncon([hamBA, rhoAB, v, np.conj(v), np.conj(w)], indList4)\n",
    "\n",
    "  return wEnv\n",
    "\n",
    "\n",
    "def IsoEnvV(hamAB, hamBA, rhoBA, rhoAB, w, v, u):\n",
    "  \"\"\" compute the environment of a 'v'-isometry \"\"\"\n",
    "\n",
    "  indList1 = [[6, 4, 1, 3], [9, 11, 8, -3], [1, 2, 8], [6, 7, 9], [3, 5, 2, -2],\n",
    "              [4, 5, 7, 10], [-1, 10, 11]]\n",
    "  indList2 = [[3, 4, 1, 2], [8, 10, 9, -3], [5, 6, 9], [5, 7, 8], [1, 2, 6, -2],\n",
    "              [3, 4, 7, 11], [-1, 11, 10]]\n",
    "  indList3 = [[9, 10, 11, -1], [3, 4, 2, -3], [1, 8, 2], [1, 5, 3],\n",
    "              [7, 11, 8, -2], [7, 9, 5, 6], [10, 6, 4]]\n",
    "  indList4 = [[7, 5, -1, 4], [6, 3, -3, 2], [7, -2, 6], [4, 1, 2], [5, 1, 3]]\n",
    "\n",
    "  vEnv = ncon(\n",
    "      [hamAB, rhoBA, w, np.conj(w), u,\n",
    "       np.conj(u), np.conj(v)], indList1)\n",
    "  vEnv = vEnv + ncon(\n",
    "      [hamBA, rhoBA, w, np.conj(w), u,\n",
    "       np.conj(u), np.conj(v)], indList2)\n",
    "  vEnv = vEnv + ncon(\n",
    "      [hamAB, rhoBA, w, np.conj(w), u,\n",
    "       np.conj(u), np.conj(v)], indList3)\n",
    "  vEnv = vEnv + ncon([hamBA, rhoAB, np.conj(v), w, np.conj(w)], indList4)\n",
    "\n",
    "  return vEnv\n",
    "\n",
    "\n",
    "def TensorExpand(A, chivec):\n",
    "  \"\"\" expand tensor dimension by padding with zeros \"\"\"\n",
    "\n",
    "  if [*A.shape] == chivec:\n",
    "    return A\n",
    "  else:\n",
    "    for k in range(len(chivec)):\n",
    "      if A.shape[k] != chivec[k]:\n",
    "        indloc = list(range(-1, -len(chivec) - 1, -1))\n",
    "        indloc[k] = 1\n",
    "        A = ncon([A, np.eye(A.shape[k], chivec[k])], [indloc, [1, -k - 1]])\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def TensorUpdateSVD(wIn, leftnum):\n",
    "  \"\"\" update an isometry using its (linearized) environment \"\"\"\n",
    "\n",
    "  wSh = wIn.shape\n",
    "  ut, st, vht = LA.svd(\n",
    "      wIn.reshape(np.prod(wSh[0:leftnum:1]), np.prod(wSh[leftnum:len(wSh):1])),\n",
    "      full_matrices=False)\n",
    "  return -(ut @ vht).reshape(wSh)\n",
    "\n",
    "\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "# doConformalMERA.py\n",
    "# ---------------------------------------------------------------------\n",
    "# Extraction of conformal data from an optimised MERA\n",
    "#\n",
    "# by Glen Evenbly (c) for www.tensors.net, (v1.2) - last modified 6/2019\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from scipy.sparse.linalg import eigs\n",
    "from ncon import ncon\n",
    "\n",
    "\n",
    "def doConformalMERA(wS, uS, vS, rhoBAS, scnum):\n",
    "  \"\"\"\n",
    "  Compute conformal data from an modified binary MERA optimized for a\n",
    "  scale-invariant critical point. Input 'ws', 'vs' and 'uS' are the\n",
    "  isometries and disentangler from the scale-invariant layers, while\n",
    "  'rhoBAS' is the fixed point density matrix. 'scnum' sets the number of\n",
    "  scaling dimensions to compute.\n",
    "\n",
    "  Outputs 'scDims', 'scOps', and 'Cfusion' are the scaling dimensions,\n",
    "  scaling operators and fusion coefficients respectively.\n",
    "  \"\"\"\n",
    "\n",
    "  # Diagonalize 1-site scaling superoperator\n",
    "  chi = wS.shape[2]\n",
    "  tensors = [wS, np.conj(wS), vS, np.conj(vS)]\n",
    "  connects = [[-4, 1, 3], [-3, 1, 4], [3, 2, -2], [4, 2, -1]]\n",
    "  ScSuper1 = ncon(tensors, connects).reshape(chi**2, chi**2)\n",
    "\n",
    "  dtemp, utemp = eigs(ScSuper1, k=scnum, which='LM')\n",
    "  scDims = -np.log2(abs(dtemp)) / 2\n",
    "\n",
    "  # Normalize scaling operators\n",
    "  scOps = [0 for x in range(scnum)]\n",
    "  for k in range(scnum):\n",
    "    scAtemp = utemp[:, k].reshape(chi, chi)\n",
    "    scAtemp = scAtemp / LA.norm(scAtemp)\n",
    "\n",
    "    tensors = [scAtemp, scAtemp, wS, np.conj(wS), uS, np.conj(uS), vS,\n",
    "               np.conj(vS), rhoBAS]\n",
    "    connects = [[8, 7], [3, 1], [7, 9, 11], [8, 10, 13], [2, 1, 9, 5],\n",
    "                [2, 3, 10, 6], [4, 5, 12], [4, 6, 14], [13, 14, 11, 12]]\n",
    "    cweight = ncon(tensors, connects)\n",
    "    scOps[k] = scAtemp / np.sqrt(cweight)\n",
    "\n",
    "  # Compute fusion coefficients (OPE coefficients)\n",
    "  Cfusion = np.zeros((scnum, scnum, scnum), dtype=complex)\n",
    "  for k1 in range(scnum):\n",
    "    for k2 in range(scnum):\n",
    "      for k3 in range(scnum):\n",
    "        Otemp = scDims[k1] - scDims[k2] + scDims[k3]\n",
    "        tensors = [scOps[k1], scOps[k2], scOps[k3], wS, np.conj(wS), uS,\n",
    "                   np.conj(uS), vS, np.conj(vS), uS, np.conj(uS), wS,\n",
    "                   np.conj(wS), wS, np.conj(wS), vS, np.conj(vS), rhoBAS]\n",
    "        connects = [[5, 4], [3, 1], [28, 27], [4, 6, 11], [5, 7, 13],\n",
    "                    [2, 1, 6, 9], [2, 3, 7, 10], [8, 9, 12], [8, 10, 14],\n",
    "                    [11, 12, 16, 21], [13, 14, 17, 23], [15, 16, 18],\n",
    "                    [15, 17, 19], [27, 26, 24], [28, 26, 25], [24, 21, 20],\n",
    "                    [25, 23, 22], [19, 22, 18, 20]]\n",
    "        Cfusion[k1, k2, k3] = (2**Otemp) * ncon(tensors, connects)\n",
    "\n",
    "  return scDims, scOps, Cfusion\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "  \n",
    "# mainVarMERA.py\n",
    "# ---------------------------------------------------------------------\n",
    "# Script file for initializing the Hamiltonian and MERA tensors before\n",
    "# passing to a variational energy minimization routine. Initiates the\n",
    "# extraction of conformal data from MERA after the minimization is complete.\n",
    "#\n",
    "# by Glen Evenbly (c) for www.tensors.net, (v1.2) - last modified 6/2019\n",
    "\n",
    "\n",
    "# Preamble\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from doVarMERA import doVarMERA\n",
    "from doConformalMERA import doConformalMERA\n",
    "\n",
    "# Example 1: crit Ising model #####\n",
    "#######################################\n",
    "\n",
    "# Set bond dimensions and simulation options\n",
    "chi = 6\n",
    "chimid = 4\n",
    "\n",
    "OPTS = {'numiter': 2000,  # number of variatonal iterations\n",
    "        'refsym': True,  # impose reflection symmetry\n",
    "        'numtrans': 1,  # number of transitional layers\n",
    "        'dispon': True,  # display convergence data\n",
    "        'E0': -4 / np.pi,  # specify exact ground energy (if known)\n",
    "        'sciter': 4}  # iterations of power method to find density matrix\n",
    "\n",
    "# Define Hamiltonian (quantum critical Ising), do preliminary 2->1 blocking\n",
    "OPTS['numtrans'] = int(max(OPTS['numtrans'],\n",
    "                           np.ceil(np.log(chi) / (2 * np.log(4)))))\n",
    "sX = np.array([[0, 1], [1, 0]], dtype=float)\n",
    "sZ = np.array([[1, 0], [0, -1]], dtype=float)\n",
    "htemp = -np.kron(sX, sX) - 0.5 * (\n",
    "    np.kron(sZ, np.eye(2)) + np.kron(np.eye(2), sZ))\n",
    "hbig = (0.5 * np.kron(np.eye(4), htemp) +\n",
    "        np.kron(np.eye(2), np.kron(htemp, np.eye(2))) +\n",
    "        0.5 * np.kron(htemp, np.eye(4))).reshape(2, 2, 2, 2, 2, 2, 2, 2)\n",
    "hamAB = [0] * (OPTS['numtrans'] + 2)\n",
    "hamBA = [0] * (OPTS['numtrans'] + 2)\n",
    "hamAB[0] = (hbig.transpose(0, 1, 3, 2, 4, 5, 7, 6)).reshape(4, 4, 4, 4)\n",
    "hamBA[0] = (hbig.transpose(1, 0, 2, 3, 5, 4, 6, 7)).reshape(4, 4, 4, 4)\n",
    "\n",
    "# Initialize tensors\n",
    "totLv = OPTS['numtrans'] + 1\n",
    "chiZ = np.zeros(totLv + 1, dtype=int)\n",
    "chiZ[0] = hamAB[0].shape[0]\n",
    "chimidZ = np.zeros(totLv + 1, dtype=int)\n",
    "chimidZ[0] = hamAB[0].shape[0]\n",
    "for k in range(totLv):\n",
    "  chiZ[k + 1] = min(chi, chiZ[k] * chimidZ[k])\n",
    "  chimidZ[k + 1] = min(chimid, chiZ[k + 1])\n",
    "\n",
    "wC = [0] * (OPTS['numtrans'] + 1)\n",
    "vC = [0] * (OPTS['numtrans'] + 1)\n",
    "uC = [0] * (OPTS['numtrans'] + 1)\n",
    "for k in range(totLv):\n",
    "  wC[k] = np.random.rand(chiZ[k], chimidZ[k], chiZ[k + 1])\n",
    "  vC[k] = np.random.rand(chiZ[k], chimidZ[k], chiZ[k + 1])\n",
    "  uC[k] = (np.eye(chiZ[k]**2, chimidZ[k]**2)).reshape(chiZ[k], chiZ[k],\n",
    "                                                      chimidZ[k], chimidZ[k])\n",
    "\n",
    "rhoAB = [0] * (OPTS['numtrans'] + 2)\n",
    "rhoBA = [0] * (OPTS['numtrans'] + 2)\n",
    "rhoAB[0] = np.eye(chiZ[0]**2).reshape(chiZ[0], chiZ[0], chiZ[0], chiZ[0])\n",
    "rhoBA[0] = np.eye(chiZ[0]**2).reshape(chiZ[0], chiZ[0], chiZ[0], chiZ[0])\n",
    "for k in range(totLv):\n",
    "  rhoAB[k + 1] = np.eye(chiZ[k + 1]**2).reshape(chiZ[k + 1], chiZ[k + 1],\n",
    "                                                chiZ[k + 1], chiZ[k + 1])\n",
    "  rhoBA[k + 1] = np.eye(chiZ[k + 1]**2).reshape(chiZ[k + 1], chiZ[k + 1],\n",
    "                                                chiZ[k + 1], chiZ[k + 1])\n",
    "  hamAB[k + 1] = np.zeros((chiZ[k + 1], chiZ[k + 1], chiZ[k + 1], chiZ[k + 1]))\n",
    "  hamBA[k + 1] = np.zeros((chiZ[k + 1], chiZ[k + 1], chiZ[k + 1], chiZ[k + 1]))\n",
    "\n",
    "# Perform variational optimization\n",
    "Energy, hamAB, hamBA, rhoAB, rhoBA, wC, vC, uC = doVarMERA(\n",
    "    hamAB, hamBA, rhoAB, rhoBA, wC, vC, uC, chi, chimid, OPTS)\n",
    "\n",
    "# Expand bond dimension and increase number of transitional layers,\n",
    "# then continue variational optimization\n",
    "chi = 8\n",
    "chimid = 6\n",
    "OPTS['numtrans'] = 2\n",
    "OPTS['numiter'] = 1800\n",
    "Energy, hamAB, hamBA, rhoAB, rhoBA, wC, vC, uC = doVarMERA(\n",
    "    hamAB, hamBA, rhoAB, rhoBA, wC, vC, uC, chi, chimid, OPTS)\n",
    "\n",
    "# Expand bond dimension and increase number of transitional layers,\n",
    "# then continue variational optimization\n",
    "chi = 12\n",
    "chimid = 8\n",
    "OPTS['numtrans'] = 3\n",
    "OPTS['numiter'] = 1400\n",
    "Energy, hamAB, hamBA, rhoAB, rhoBA, wC, vC, uC = doVarMERA(\n",
    "    hamAB, hamBA, rhoAB, rhoBA, wC, vC, uC, chi, chimid, OPTS)\n",
    "\n",
    "# Compute the conformal data from the optimized MERA\n",
    "scnum = 10\n",
    "scDims, scOps, Cfusion = doConformalMERA(wC[-1], uC[-1], vC[-1],\n",
    "                                         rhoBA[-1], scnum)\n",
    "\n",
    "# Compare with known results for Ising CFT\n",
    "scDimsExact = [0, 1 / 8, 1, 1 + 1 / 8, 1 + 1 / 8, 2, 2, 2, 2, 2 + 1 / 8]\n",
    "plt.figure(1)\n",
    "plt.plot(range(scnum), scDimsExact, 'b', label=\"exact\")\n",
    "plt.plot(range(scnum), scDims, 'rx', label=\"MERA\")\n",
    "plt.legend()\n",
    "plt.title('critical Ising model')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Scaling Dims: Delta_k')\n",
    "plt.show()\n",
    "\n",
    "Cess = [Cfusion[1, 1, 2], Cfusion[1, 2, 1], Cfusion[2, 1, 1]]\n",
    "CessExact = [0.5, 0.5, 0.5]\n",
    "print('Fusion coefficients: Exact_C(ep,sg,sg) = %f, MERA_C(ep,sg,sg) = %f' %\n",
    "      (CessExact[1], np.real(Cess[1])))\n",
    "\n",
    "# Save data\n",
    "np.save('IsingData.npy', (wC, uC, vC, rhoAB, rhoBA))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
